<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Project Topic Two</title>
    <link rel="stylesheet" href="../../Styles/semanticui/semantic.min.css">
    <link rel="stylesheet" href="../../Styles/common.css">
    <srcipt src="../../Styles/semanticui/semantic.min.js"></srcipt>
</head>

<body>
    <!-- Header -->
    <div class="ui masthead vertical segment">
        <center>
            <h1 class="ui header">Machine Learning
                <div class="sub header">
                    SUSTech 2017 Fall Semester
                    <br>CSE5009(CS405)
                    <br>Lecture and Lab Materials
                    <br>
                    <a href="http://cse.sustc.edu.cn/cn/people/view/people_id/5/sort_id/9/pid/" target="_blank">Qi HAO</a>
                    <br>
                </div>
            </h1>
        </center>
    </div>

    <div class="main ui container">
        <a href="../../index.html">&lt; &lt; &lt; </a>
        <h2 class="ui dividing header">Topic Two: Video Related Simulation Data Generation with GAN</h2>

        <h3 class="ui header">Single-view video</h3>
        <p>
            UCF101 is an action recognition data set of realistic action videos, collected from YouTube, having 101 action categories. Generative adversarial networks (GANs) should be used for generating video in this project. Tasks should be completed include:
        </p>
        <ul>
            <li>Predict future (the last “v_ApplyEyeMakeup_gc01 video of each series), for example, 05.avi” is train data, “v_ApplyEyeMakeup_gc06.avi”-is test data.</li>
            <li>Similar but different video need to be generated, and the actions of generated video should be the same as UCF101 dataset.</li>
        </ul>

        <p>
            Dataset1: <a href="http://pan.baidu.com/s/1bphf4fX" target="_blank">link</a>
            <br>
            password:<code>ebzk</code>
        </p>
        <p>
            Dataset2: <a href="http://pan.baidu.com/s/1i4WJPat" target="_blank">link</a>
            <br>
            password:<code>qw60</code>
        </p>

        <h4 class="ui header">Other useful open-source demos</h4>
        <p>
            <a href="https://github.com/dyelax/Adversarial_Video_Generation" target="_blank">link1</a>
        </p>
        <p>
            <a href="https://github.com/neka-nat/chainer-videogan" target="_blank">link2</a>
        </p>
        
        <div class="ui divider"></div>

        <h3 class="ui header">Single-view video</h3>
        <p>
            WVU multi-view action recognition dataset 1 includes 12 actions, and data of subjects are collected from different views using a network of 8 embedded cameras. Try to get new video by GANs, the challenge of this task is the correlation among 8 cameras.
        </p>
        <p>
            We only use <a href="http://community.wvu.edu/~vkkulathumani/wvu-action.html#download2" target="_blank">dataset1</a>.
        </p>     

        <div class="ui divider"></div>


    </div>
</body>

</html>